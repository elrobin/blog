[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Do not read",
    "section": "",
    "text": "Altmetrics and Open Science @ Napoli SSSM\n\n\n\n\n\n\ntalks\n\n\n\n\n\n\n\n\n\nJun 13, 2025\n\n\nN. Robinson-Garcia\n\n\n\n\n\n\n\n\n\n\n\n\nMaterials on scientific publishing and OA\n\n\n\n\n\n\ntalks\n\n\n\n\n\n\n\n\n\nMay 30, 2025\n\n\nN. Robinson-Garcia\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the social organization of the sciences\n\n\n\n\n\n\ntalks\n\n\n\n\n\n\n\n\n\nMay 23, 2025\n\n\nN. Robinson-Garcia\n\n\n\n\n\n\n\n\n\n\n\n\nReading on African collaboration patterns\n\n\n\n\n\n\nreviews\n\n\n\n\n\n\n\n\n\nJan 13, 2025\n\n\nN. Robinson-Garcia\n\n\n\n\n\n\n\n\n\n\n\n\nDownloading data from Scopus API\n\n\n\n\n\n\ncoding\n\n\n\n\n\n\n\n\n\nNov 27, 2024\n\n\nN. Robinson-Garcia\n\n\n\n\n\n\n\n\n\n\n\n\nMore on multiauthorship\n\n\n\n\n\n\nreviews\n\n\n\n\n\n\n\n\n\nNov 26, 2024\n\n\nN. Robinson-Garcia\n\n\n\n\n\n\n\n\n\n\n\n\nScientific authorship and dealing with multiauthorship\n\n\n\n\n\n\nreviews\n\n\n\n\n\n\n\n\n\nNov 25, 2024\n\n\nN. Robinson-Garcia\n\n\n\n\n\n\n\n\n\n\n\n\nHello world\n\n\n\n\n\n\ngibberish\n\n\n\n\n\n\n\n\n\nNov 24, 2024\n\n\nN. Robinson-Garcia\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/26-11-2024/index.html",
    "href": "posts/26-11-2024/index.html",
    "title": "More on multiauthorship",
    "section": "",
    "text": "Image generated with DALL-E\n\n\nLately I am very interested on authorship and more specifically, on the problems this concept brings in terms of allocation of credit among researchers given the current collaborative nature of research. This is very much related to the book I am writing on diversity and recognition in academia.\nHere some notes for some of the papers I am reading.\nCronin, B. (2001). Hyperauthorship: A postmodern perversion or evidence of a structural shift in scholarly communication practices? Journal of the American Society for Information Science and Technology, 52(7), 558‚Äì569. https://doi.org/10.1002/asi.1097\nHe focuses on the issues arising in biomedical sciences with regard to honorary authorship and authorship inflation. Takes a historical perspective, from the birth of scientific authorship to the development of the current scientific publishing system. It discusses disciplinary differences on authorship order. Authorship is tied to credit and responsibility, but also is linked with an individualistic notion and not a collective endeavour which is an anachronistic conception of science.\nCollaboration becomes a reality especially after WWII, with the expansion of ‚Äòbig science‚Äô which required funding, infrastructure and coordination and management. Currently it is the norm, with some fields and projects requiring the development of an internal structure and division of labour while others are more informal levels of collaboration. He mentions the suggestion by (Rennie, Yank, and Emanuel 1997) of abandoning the concept of author in favour of alternatives such as contributor or guarantor. As we know this proposal later gained track within the biomedical sciences with the CRediT taxonomy becoming a NISO standard more than 15 years later (Allen et al. 2014). This has to do with the inefficacy of the initial solution proposed by ICMJE which was to make all authors responsible of the complete content of a paper.\nStill, Cronin is critical with this proposal because it is still difficult to enforce responsibility in cases of what he terms hyperauthorship. He entertains the idea of using the ‚ÄòAcknowledgements‚Äô section for contributions of second order, but recognizes also its limitations. Finally, he discusses the HEP model where all the recognition and authorship discussions are ridden internally, while an external observer would be incapable of administrating credit through authorship.\nWalsh, J. P., & Lee, Y.-N. (2015). The bureaucratization of science. Research Policy, 44(8), 1584‚Äì1600. https://doi.org/10.1016/j.respol.2015.04.010\nThis paper examines how scientific teams organize internally based on their size, interdisciplinarity and task interdependence. It uses organizational theory (similarly to (Whitley 2000)) and emphasizes the importance of internal structure to ensure a successful performance. They make some interesting points, such as the changes on the training model of scientists from the apprentice-model kind of model suggested by (Laudel and Gl√§ser 2008) (although not cited in the paper) to an industrialized model of scientific careers with more of a professor-employer kind of model. Again they bring up the misalignment between credit allocation and multiauthorship.\n\n\n\n\nReferences\n\nAllen, Liz, Jo Scott, Amy Brand, Marjorie Hlava, and Micah Altman. 2014. ‚ÄúPublishing: Credit Where Credit Is Due.‚Äù Nature 508 (7496): 312‚Äì13. https://doi.org/10.1038/508312a.\n\n\nLaudel, Grit, and Jochen Gl√§ser. 2008. ‚ÄúFrom Apprentice to Colleague: The Metamorphosis of Early Career Researchers.‚Äù Higher Education 55 (3): 387‚Äì406. https://doi.org/10.1007/s10734-007-9063-7.\n\n\nRennie, Drummond, Veronica Yank, and Linda Emanuel. 1997. ‚ÄúWhen Authorship Fails: A Proposal to Make Contributors Accountable.‚Äù JAMA 278 (7): 579‚Äì85. https://doi.org/10.1001/jama.1997.03550070071041.\n\n\nWhitley, Richard. 2000. The Intellectual and Social Organization of the Sciences. 2nd ed. Oxford: Oxford University Press."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/24-11-2024/index.html",
    "href": "posts/24-11-2024/index.html",
    "title": "Scientific authorship and dealing with multiauthorship",
    "section": "",
    "text": "Illustration from Davis Parkins, Source: Nature\n\n\nNotes from Biagioli, M. (2013). Rights or Rewards? Changing Frameworks of Scientific Authorship. In M. Biagioli & P. Gallison (eds) Scientific Authorship: Credit and Intellectual Property in Science (1st ed., pp.¬†253-279). Routledge.\n\nScientific authorship is a misnomer, a historical vestige. Mario Biagioli, p.¬†274\n\nThe problems derived from using authorship as an attribution of credit in times of Big Science are a common issue for those studying the social dynamics of science through the use of publications. Authorship and author order are extremely polluted by seniority and power dynamics, furthermore, authorship seems a limited concept for reflecting each author‚Äôs contribution and responsibility, especially when dealing with papers produced by large teams.\nScientific authorship is considered a symbolic reward not attached to the specific object (the article) but to the true claims made in such object, and it is given by peers. This means that ‚Äúa scientific claim does not count as such unless it is made public and subjected to peer evaluation‚Äù (p.¬†254). Multiauthorship includes a layer of complexity to the evaluation of scientific performance, as it introduces ambiguity: evaluators have to assess the value of the paper and the share of such value attributed to the candidate. ‚Äú[T]he economy of science is inherently based on trust‚Äù (p.¬†260). The author argues that copyright does not hold for our understanding of scientific author and hence proposes a redefinition.\nHe revises how two different fields approached to this issue. The first one is the biomedical sciences. IMCJE‚Äôs first solution to this issue, was to reinforce the figure of the author in the traditional sense, which does not work in highly stratified science formed by dozens or even hundreds of authors. Hence it moved towards the concept of contributorship, where team members indicate their specific contribution to a given output, with the order of contributors reflecting the importance of such contribution. One of those contributors would play the role of the guarantor, that is, the person(s) who is responsible for overseeing the whole study and coordinating.\nThe second approach comes from high energy physics, instead of approaching authorship as a matter of responsibility and ownership, it considers it a matter of labour recognition. There is a Standard Author List for all people who have contributed in any way to a given lab or research centre, regardless of their involvement on specific papers or projects, and they appear alphabetically. To be part of this list, researchers have to compromise a share of their time and work, and this list is updated biannually by a committee. Furthermore, leaves of absence are allowed of up to a year without meaning being removed from the list, and researchers are even recognized a year after being removed from the list, as a way to recognize that contributions can be direct or indirect and are cumulative. In this second setting, authorship does not have the same value or credit as in biomedical sciences, and prestige and recognition operate differently through recommendation letters and internal dynamics and correspondence.\nThe review process in high energy physics operates in a different way to what we know from other fields. After a subgroup from the Standard Author List writes up a manuscript, it is submitted internally to all members of the list, who are asked to comment electronically. The paper goes three rounds of internal reviews and then, members of the list who still disagree with the contents, remove their name from the manuscript, hence here less authors would equate to less acceptance. As all the validation process is internal, so are issues with research integrity, fraud or misconduct.\nHence, Biagioli concludes indicating that scientific authorship is a tied more to disciplinary ecologies and the economy of science rather than to a legal category, more related with responsibility and disciplinary norms."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Hello world",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/27-11-2024/index.html",
    "href": "posts/27-11-2024/index.html",
    "title": "Downloading data from Scopus API",
    "section": "",
    "text": "This is a small tutorial on how to work with the Scopus API using R. Most bibliographic databases allow nowadays downloading bibliographic data through their API in an automated way if you are registered and have an institutional subscription. In many cases, they lack of a good documentation, this is not the case for Elsevier, who have quite a lot of info on how to work with their data."
  },
  {
    "objectID": "posts/27-11-2024/index.html#step-1.-setup-api-access",
    "href": "posts/27-11-2024/index.html#step-1.-setup-api-access",
    "title": "Downloading data from Scopus API",
    "section": "Step 1. Setup API Access",
    "text": "Step 1. Setup API Access\nFirst thing you need to do is to go to the Elsevier Developers Portal and request an API Key.\n\nWhen you request a key, it asks you to access through your institutional account and will register an API key under your profile."
  },
  {
    "objectID": "posts/27-11-2024/index.html#step-2.-environment-setup",
    "href": "posts/27-11-2024/index.html#step-2.-environment-setup",
    "title": "Downloading data from Scopus API",
    "section": "Step 2. Environment setup",
    "text": "Step 2. Environment setup\nNow it is time to make sure we have all the packages needed to download and process data. These are:\n\nhttr. Provides functions for working with HTTP requests and responses, making it easy to interact with web APIs\njsonlite. A package to parse, process and generate JSON data.\ntidyverse. A collection of R packages for data manipulation, visualization and analysis. Helps to organize and work with data retrieved from the API.\n\n\n# load libraries\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter()  masks stats::filter()\n‚úñ purrr::flatten() masks jsonlite::flatten()\n‚úñ dplyr::lag()     masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nNext step is to store the API key in an .Renviron file. For this we first need to open the .Renviron file in RStudio:\n\nfile.edit(\"~/.Renviron\")\n\nAdd a new line to the file with this info:\n\nSCOPUS_API_KEY=your_api_key_here\n\nNow let‚Äôs try it works:\n\n# Retrieve API from .Renviron\napi_key &lt;- Sys.getenv(\"SCOPUS_API_KEY\")\n\n# Test API call to check validity of the key\nresponse &lt;- GET(\"https://api.elsevier.com/content/search/scopus\",\n                add_headers(\"X-ELS-APIKey\" = api_key),\n                query = list(query = \"AUTHOR-NAME(Robinson-Garcia)\", count = 1))\n\n# Check status\nif (status_code(response) == 200) {\n  print(\"API key is valid and working.\")\n} else {\n  print(paste(\"Error:\", status_code(response), \"Check your API key or access permissions.\"))\n}\n\n[1] \"API key is valid and working.\""
  },
  {
    "objectID": "posts/27-11-2024/index.html#step-3.-reading-and-preparing-the-list-of-author-ids",
    "href": "posts/27-11-2024/index.html#step-3.-reading-and-preparing-the-list-of-author-ids",
    "title": "Downloading data from Scopus API",
    "section": "Step 3. Reading and preparing the list of Author IDs",
    "text": "Step 3. Reading and preparing the list of Author IDs\nIn my case I already have a list of publications with their author IDs per row. I want to work only with the Author IDs and clean it so that I have one by row in a vector for querying later on the API.\n\nlibrary(readr)     # For reading the CSV file\n\n# Step 1: Import the CSV file\n# Replace \"your_file.csv\" with your actual file path\ndata &lt;- read_csv(\"G:/Mi unidad/1. Work sync/Projects/z2025_01-SELECT/Contributions-inequalites/raw_data/contrib_data.csv\")\n\nRows: 675080 Columns: 29\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (7): doi, auid_list, affiliation_id_list, author_affiliation_mapping, s...\ndbl (22): Eid, Year, n_authors, source_id, CitationCount, DDR, DDA, SV_topic...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Step 2: Extract and clean the 'auid_list' column\nauthor_ids &lt;- data %&gt;%\n  select(auid_list) %&gt;%               # Select the relevant column\n  separate_rows(auid_list, sep = \",\") %&gt;% # Split each row by commas\n  mutate(auid_list = str_trim(auid_list)) %&gt;% # Trim whitespace\n  distinct(auid_list) %&gt;%                 # Remove duplicate IDs\n  pull(auid_list)                         # Extract as a vector\n\n# Optional: Check the length of the vector\nlength(author_ids)\n\n[1] 2082499\n\n\nI end up with over 2M authors."
  },
  {
    "objectID": "posts/27-11-2024/index.html#step-4.-query-the-api-for-metadata",
    "href": "posts/27-11-2024/index.html#step-4.-query-the-api-for-metadata",
    "title": "Downloading data from Scopus API",
    "section": "Step 4. Query the API for metadata",
    "text": "Step 4. Query the API for metadata\nLet‚Äôs create a function to download the data we want:\n\n# Function to query Scopus API for author metadata\nquery_author &lt;- function(author_id, api_key, output_dir = \"author_data\") {\n  # Ensure the output directory exists\n  if (!dir.exists(output_dir)) dir.create(output_dir)\n  \n  # Construct the API URL\n  url &lt;- paste0(\"https://api.elsevier.com/content/author/author_id/\", author_id)\n  \n  # Query the API\n  response &lt;- GET(url,\n                  add_headers(\"X-ELS-APIKey\" = api_key),\n                  query = list(httpAccept = \"application/json\"))\n  \n  if (status_code(response) == 200) {\n    # Parse the response content\n    content_raw &lt;- content(response, as = \"text\", encoding = \"UTF-8\")\n    content &lt;- fromJSON(content_raw)\n    \n    # Save to a JSON file\n    output_file &lt;- file.path(output_dir, paste0(author_id, \".json\"))\n    write_json(content, output_file, pretty = TRUE)\n    return(TRUE)  # Indicate success\n  } else {\n    # Log the error\n    print(paste(\"Error: Status code\", status_code(response), \"for author ID:\", author_id))\n    return(FALSE)  # Indicate failure\n  }\n}\n\nAnd now a test to see if everything works:\n\nau_data &lt;- query_author(\"36712349900\", api_key)\nprint(au_data)\n\n[1] TRUE"
  },
  {
    "objectID": "posts/27-11-2024/index.html#step-4.-create-loop-and-download",
    "href": "posts/27-11-2024/index.html#step-4.-create-loop-and-download",
    "title": "Downloading data from Scopus API",
    "section": "Step 4. Create loop and download",
    "text": "Step 4. Create loop and download\n\n1. Create the Loop and Batch Logic\n\nImplement a loop to process author IDs in batches.\nWrite a function to distribute batches across API keys for parallel processing.\n\nSteps:\n\nSplit the full list of author IDs into manageable batches.\nAssign batches to available API keys, ensuring even distribution.\nProcess each batch sequentially or in parallel using the respective API key.\nSave the results incrementally as JSON files.\n\n\n\n2. Test the Code with a Small Dataset\n\nUse a sample dataset of 100 author IDs to validate the process before scaling up.\nUse 2 API keys for this test to confirm:\n\nBatch splitting and key assignment work correctly.\nParallelization works as expected.\nJSON files are saved correctly.\n\nTest and document the maximum batch size (e.g., 100, 500, 1000 IDs per batch) that can run smoothly without exceeding memory or rate limits.\n\n\n\n3. Execute the Parallel Download with 50 API Keys\n\nAfter validating the test, set up the full process to use 50 API keys for the entire dataset.\nEnsure:\n\nAPI keys are evenly distributed across batches.\nPauses are implemented between batches if necessary to comply with API rate limits.\nAll data is saved incrementally as JSON files.\n\n\n\n\nAdditional Notes\n\nAPI Key Management:\n\nConfirm that all 50 API keys are valid and have sufficient quotas (20,000 requests/week per key).\nMonitor usage during the process to avoid exceeding limits.\n\nError Handling:\n\nEnsure failed queries are logged (e.g., into an errors.csv file) for retries later.\n\nResuming Progress:\n\nInclude a mechanism to skip already processed IDs by checking for existing JSON files in the output directory.\n\n\n\n\nNext Steps Summary\n\nBatch Testing:\n\nTest batch size limits with a small dataset of 100 IDs using 2 API keys.\n\nParallel Processing:\n\nImplement parallel processing with 50 API keys and scale up for the full dataset.\n\nError Handling & Logs:\n\nLog any failed queries for retries later.\n\nData Storage:\n\nSave each author‚Äôs data as a JSON file incrementally."
  },
  {
    "objectID": "posts/13-01-2025/index.html",
    "href": "posts/13-01-2025/index.html",
    "title": "Reading on African collaboration patterns",
    "section": "",
    "text": "‚ÄòThe Sleeping Sickness‚Äô ‚Äî American cartoon published in Puck magazine, 1911, showing European nations colonising Africa while a giant African man lies against a tree. Artist: Gordon Ross.\nHere some self-notes on my readings regarding African collaboration dynamics. I include the reference and some notes pointing at things relevant to the work I am doing right now and probably useless from everyone else üôÑ."
  },
  {
    "objectID": "posts/13-01-2025/index.html#inequalities",
    "href": "posts/13-01-2025/index.html#inequalities",
    "title": "Reading on African collaboration patterns",
    "section": "Inequalities",
    "text": "Inequalities\nHolmarsdottir, H. B., Desai, Z., Botha, L. R., Breidlid, A., Bastien, S., Mukoma, W., Ezekiel, M. J., Helleve, A., Farag, A. I., & Nomlomo, V. (2013). COMPARE Forum: The idea of North-South and South-South collaboration. Compare: A Journal of Comparative and International Education, 43(2), 265-286. https://doi.org/10.1080/03057925.2013.765274\nThe idea that North helps South is simplistic and unrealistic, there is growing awareness and concern on the need of African countries to reassert their own research agenda to foster innovation as well as to strengthen intra-regionald and south-south collaboration networks.\nThere is a difference between internationalising research and being involved in international cooperation networks as the former should look towards global and common aims while the latter can lead (and leads) to inequalities due to power dynamics."
  },
  {
    "objectID": "posts/13-01-2025/index.html#general-patterns-and-use-of-indicators",
    "href": "posts/13-01-2025/index.html#general-patterns-and-use-of-indicators",
    "title": "Reading on African collaboration patterns",
    "section": "General patterns and use of indicators",
    "text": "General patterns and use of indicators\nConfraria, H., Mira Godinho, M., & Wang, L. (2017). Determinants of citation impact: A comparative analysis of the Global South versus the Global North. Research Policy, 46(1), 265-279. https://doi.org/10.1016/j.respol.2016.11.004\nConfraria, H., & Godinho, M. M. (2015). The impact of African science: A bibliometric analysis. Scientometrics, 102(2), 1241-1268. https://doi.org/10.1007/s11192-014-1463-8\nResearch in Africa has increased lately, although specialization seems to play a greater role in African countries as a triggering factor for impact.\nIn Confraria & Godinho (2015) there is an interesting discussion related to the adequacy of WoS to measure African output, although that is what they finally do."
  },
  {
    "objectID": "posts/13-01-2025/index.html#factors-associated-with-scientific-workforce",
    "href": "posts/13-01-2025/index.html#factors-associated-with-scientific-workforce",
    "title": "Reading on African collaboration patterns",
    "section": "Factors associated with scientific workforce",
    "text": "Factors associated with scientific workforce\nEduan, W. (2019). Influence of study abroad factors on international research collaboration: Evidence from higher education academics in sub-Saharan Africa. Studies in Higher Education, 44(4), 774-785. https://doi.org/10.1080/03075079.2017.1401060\nMobility experience improves outcomes, but is dependent on the intensity of the experience (immersion programmes, internshipst, etc.).\nEl-Ouahi, J., Robinson-Garc√≠a, N., & Costas, R. (2021). Analyzing scientific mobility and collaboration in the Middle East and North Africa. Quantitative Science Studies, 2(3), 1023-1047. https://doi.org/10.1162/qss_a_00149\nEl-Ouahi, J., & Larivi√®re, V. (2023). On the lack of women researchers in the Middle East and North Africa. Scientometrics, 128(8), 4321-4348. https://doi.org/10.1007/s11192-023-04768-5\nThese are studies focused on MENA countries disclosing regional mobility within the country and a disproportionate gender gap which affects career trajectories."
  },
  {
    "objectID": "posts/13-01-2025/index.html#specific-studies-on-fields",
    "href": "posts/13-01-2025/index.html#specific-studies-on-fields",
    "title": "Reading on African collaboration patterns",
    "section": "Specific studies on fields",
    "text": "Specific studies on fields\nMaina, M. B., Ahmad, U., Ibrahim, H. A., Hamidu, S. K., Nasr, F. E., Salihu, A. T., Abushouk, A. I., Abdurrazak, M., Awadelkareem, M. A., Amin, A., Imam, A., Akinrinade, I. D., Yakubu, A. H., Azeez, I. A., Mohammed, Y. G., Adamu, A. A., Ibrahim, H. B., Bukar, A. M., Yaro, A. U., ‚Ä¶ Baden, T. (2021). Two decades of neuroscience publication trends in Africa. Nature Communications, 12(1), Article 1. https://doi.org/10.1038/s41467-021-23784-8\nIntra-regional collaboration seems to be close-distance collaboration, long distance collaboration is normally outside the continent. There is lack of research dependent on infrastructure (e.g., state-or-the-art equipment)."
  },
  {
    "objectID": "posts/23-05-2025/index.html",
    "href": "posts/23-05-2025/index.html",
    "title": "Exploring the social organization of the sciences",
    "section": "",
    "text": "Presenting at the ATL Conference our paper on science teams\n\n\nLast week I went to the Atlanta Conference on Science and Innovation Policy, which celebrated its 10th Anniversary. This is one of my favorite conferences, very different from others I‚Äôve been to. It has a special vibe where people are really engaged and friendly, always providing constructive feedback and very opened to new ideas. Contrarily to other conferences such as ISSI or STI, the profile of the attendants is quite broad which I believe is extremely important to create interdisciplinary linkages. Plus its wonderful organizers, Julia, Diana and Cassidy.\nI had the chance to present our paper on science teams and contribution data, titled Exploring the organization of the sciences, done in collaboration with Julia Melkers, Alick Bird and Erin Leahey. In this paper we use the largest dataset (to my knowledge) on contribution statements based on Scopus data, with over 650,000 publications, and try to explore empirically Richard Whitley‚Äôs concept of task uncertainty (Whitley 2000) and the distribution of labour across fields. We do this by computing two indicators:\n\nTask entropy, which reflects the (un)balance on the distribution of tasks among authors.\nTask specialization, which looks into the average distance of the authors task profile, based on the grouping of contributions into three groups: technical tasks, conceptual tasks and management tasks.\n\nOur preliminary findings suggest a relation between team size and task uncertainty, identifying 3 types of research teams based on the balance of the task distribution: small collaboration (2-8 authors), which is the most common type of team (~85%), functional teams (9-29 authors) and super teams (30+ authors). From what we‚Äôve seen based on our approach (probably needs more refinement) disciplines do not play a big role on differences on task uncertainty.\n\n\n\n\n\n\nüóíÔ∏èCheck the slides here to learn more about our work\n\n\n\n\n\n\n\nReferences\n\nWhitley, Richard. 2000. The Intellectual and Social Organization of the Sciences. 2nd ed. Oxford: Oxford University Press."
  },
  {
    "objectID": "posts/30-05-2025/index.html",
    "href": "posts/30-05-2025/index.html",
    "title": "Materials on scientific publishing and OA",
    "section": "",
    "text": "Last Tuesday I taught the 3rd session of the course ‚ÄòC√≥mo escribir y publicar art√≠culos cient√≠ficos en Ciencias Sociales y Humanidades‚Äô. This is a course I have taught for several years along with my colleagues Daniel Torres-Salinas and Evaristo Jim√©nez-Contreras. We normally end up switching sessions based on availability and tend to change contents on the fly, but this time we went for organization and method, and Dani created a nice layout which followed a sensible workflow (you can have a look at it at the end of the post, all in Spanish).\nI was in charge of Session III and I took the baton and decided to also be methodic, and developed the following materials. I hope someone finds them useful!\n\n\n\n\n\n\n\n\n\n\n\nDownload here\n\n\n\n\n\n\n\nSESI√ìN I - Organizaci√≥n personal y planificaci√≥n del texto acad√©mico\n\nTiempo, espacio y foco\n‚ÄÉ1.1. Elecci√≥n del momento √≥ptimo para escribir\n‚ÄÉ1.2. Configuraci√≥n de un espacio personal sin distracciones\n‚ÄÉ1.3. T√©cnicas de concentraci√≥n y trabajo profundo\nNotas, m√©todo Zettelkasten y Zotero\n‚ÄÉ2.1. Importancia de la lectura activa en la escritura acad√©mica\n‚ÄÉ2.2. Aplicaci√≥n del m√©todo Zettelkasten para organizar ideas\n‚ÄÉ2.3. Uso de Zotero como herramienta de gesti√≥n de notas\nEstructura y planificaci√≥n textual\n‚ÄÉ3.1. Organizaci√≥n del contenido en un texto acad√©mico\n‚ÄÉ3.2. Dise√±o previo del guion y los p√°rrafos del texto\n‚ÄÉ3.3. Empleo de plantillas para estructurar la escritura\n\n\n\nSESI√ìN II - Estructura del art√≠culo y el ecosistema de publicaci√≥n\n\nExigencias institucionales: agencias y programas\nEl art√≠culo cient√≠fico\n‚ÄÉ2.1. Qu√© es un art√≠culo cient√≠fico\n‚ÄÉ2.2. Tipolog√≠as de resultados\n‚ÄÉ2.3. Estructura IMRyD: Introducci√≥n, Metodolog√≠a, Resultados, Discusi√≥n y Conclusiones\n‚ÄÉ2.4. Elementos adicionales: t√≠tulo, resumen, palabras clave, filiaciones\n‚ÄÉ2.5. Tablas, gr√°ficos, figuras y datos complementarios\n‚ÄÉ2.6. Bibliograf√≠a y normas editoriales\n‚ÄÉ2.7. Financiaci√≥n y agradecimientos\nRevistas cient√≠ficas e impacto\n‚ÄÉ3.1. Qu√© es una revista de impacto\n‚ÄÉ3.2. Historia y c√°lculo del factor de impacto\n‚ÄÉ3.3. Estrategias ante el rechazo editorial\n‚ÄÉ3.4. Bases de datos e indicadores: SCOPUS, Dialnet M√©tricas, CIRC\n‚ÄÉ3.5. Publicaci√≥n en monograf√≠as\nAutor√≠a y colaboraci√≥n\n‚ÄÉ4.1. Normas ICMJE y definici√≥n de autor√≠a\n‚ÄÉ4.2. Taxonom√≠a CRediT\n‚ÄÉ4.3. Malas pr√°cticas de autor√≠a\n\n\n\nSESI√ìN III - Publicaci√≥n, acceso abierto y √©tica cient√≠fica\n\nSelecci√≥n de revistas y preparaci√≥n del manuscrito\n‚ÄÉ1.1. Selecci√≥n adecuada de la revista\n‚ÄÉ1.2. Carta de remisi√≥n\nGesti√≥n de datos y reproducibilidad\n‚ÄÉ2.1. Reproducibilidad y data sharing\n‚ÄÉ2.2. Repositorios\nEnv√≠o y evaluaci√≥n del manuscrito\n‚ÄÉ3.1. Revisi√≥n por pares y tipos de evaluaci√≥n\n‚ÄÉ3.2. Herramientas del proceso editorial\n‚ÄÉ3.3. Decisiones editoriales y respuesta a revisores\nAcceso Abierto\n‚ÄÉ4.1. Tipos de Acceso Abierto\n‚ÄÉ4.2. Revistas en acceso abierto\n‚ÄÉ4.3. Revistas depredadoras\n√âtica de la publicaci√≥n cient√≠fica\n‚ÄÉ5.1. Malas pr√°cticas y prevenci√≥n\nDivulgaci√≥n cient√≠fica y visibilidad del art√≠culo publicado\n‚ÄÉ6.1. Difusi√≥n en redes acad√©micas y cient√≠ficas\n‚ÄÉ6.2. Perfil digital de investigador (ORCID, Google Scholar, etc.)\n‚ÄÉ6.3. M√©tricas alternativas (altmetrics)\nConsejos finales para publicar con √©xito"
  },
  {
    "objectID": "posts/13-06-2025/index.html",
    "href": "posts/13-06-2025/index.html",
    "title": "Altmetrics and Open Science @ Napoli SSSM",
    "section": "",
    "text": "Napoli recently won its 4th Scudetto and of course, the city was a big party\n\n\nLast Monday I had the chance to participate as an invited speaker in the I International Edition of the Summer School in Science Mapping organized by research team led by Massimo Aria and Corrado Cuccurullo. These are the people behind the wonderful R package Bibliometrix, and now also TaLL (for text analysis). It is a really nice and smart group of people, doing a fantastic job on the development of tools that can be used both, for people with and w/o programming skills. I have been in touch with them for several years, as we have invited them in several occasions to the ESSS to introduce students to their software, and even Dani created a videotutorial in Spanish for the Biblioshiny interface and I‚Äôve used it for my teaching.\nIn this occasion I was invited to talk about Altmetrics and Open Science, based on previous lectures I periodically give at the ESSS. I took the occasion to improve my materials, update them and improve the narrative. The lecture went well with an interesting follow up given the multidisciplinary background of the students.\n\n\n\n\n\n\nDownload the slides here"
  }
]